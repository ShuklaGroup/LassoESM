{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d77b4a-f6ac-4dcf-a3a0-53375bcbafde",
   "metadata": {},
   "source": [
    "# **Example notebook for extracting embeddings**\n",
    "**This notebook demonstrates how to extract embeddings for lasso peptide sequences from VanillaESM, PeptideESM and LassoESM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67755053-bf78-45b0-80b2-f35fd3b4f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f6d045-48be-4d8a-b5bb-ab5891307468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc55ef9-332e-476b-a8ac-f2b8cfe15f01",
   "metadata": {},
   "source": [
    "**Configuration for different models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61b15b46-fd19-4181-887e-1a41ff5c9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Lasso_ESM\": {\n",
    "        \"model_path\": \"ShuklaGroupIllinois/LassoESM\",\n",
    "        \"output_file\": \"FusA_LassoESM.npy\",                 # The embedding matrix is saved in \"data\" folder\n",
    "    },\n",
    "    \"VanillaESM\": {\n",
    "        \"model_path\": \"facebook/esm2_t33_650M_UR50D\",\n",
    "        \"output_file\": \"FusA_VanillaESM.npy\",\n",
    "    },\n",
    "    \"PeptideESM\": {\n",
    "        \"model_path\": \"ShuklaGroupIllinois/PeptideESM2_650M\",\n",
    "        \"output_file\": \"FusA_PeptideESM_650M.npy\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03f9d2b-696d-4e7f-bfb2-458c07cd0fe8",
   "metadata": {},
   "source": [
    "**Function to extract mean embeddings for lasso peptide sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c0e1dba-a023-4016-9e33-4a136fbccfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_rep(sequence, model, tokenizer):\n",
    "    token_ids = tokenizer(sequence, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        results = model(token_ids.input_ids, output_hidden_states=True)\n",
    "    representations = results.hidden_states[-1][0]  # Use the last hidden layer\n",
    "    mean_embedding = representations.mean(dim=0)\n",
    "    return mean_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed88ae-0505-4822-b13a-dcb55427ebea",
   "metadata": {},
   "source": [
    "**Main function to process embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71774bb8-ac9f-456f-9769-8a2118f190c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embeddings(data_file, model_name):\n",
    "    if model_name not in MODELS:\n",
    "        raise ValueError(f\"Model {model_name} not configured. Available models: {list(MODELS.keys())}\")\n",
    "    \n",
    "    config = MODELS[model_name]\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    \n",
    "    model = AutoModelForMaskedLM.from_pretrained(config[\"model_path\"]).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config[\"model_path\"])\n",
    "    model.eval()\n",
    "    \n",
    "    # Load data\n",
    "    data = pd.read_csv(data_file)\n",
    "    seq_ls = data.iloc[:, 0].tolist()  # Extract sequences from the first column\n",
    "    print(f\"Number of sequences: {len(seq_ls)}\")\n",
    "    \n",
    "    # Extract embeddings\n",
    "    seq_embs = [get_mean_rep(seq, model, tokenizer) for seq in seq_ls]\n",
    "    seq_embs = np.array(seq_embs)\n",
    "    \n",
    "    # Save embeddings\n",
    "    np.save(config[\"output_file\"], seq_embs)\n",
    "    print(f\"Embeddings saved to: {config['output_file']}\")\n",
    "    print(f\"Shape of embeddings: {seq_embs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0699359d-223e-4643-be30-7c42d33955bb",
   "metadata": {},
   "source": [
    "**Example usage: Extract embeddings for fusilassin sequences from VanillaESM, PeptideESM and LassoESM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bf2faff-0ff3-4807-bc39-a17670ac820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Lasso_ESM\n",
      "Number of sequences: 1121\n",
      "Embeddings saved to: FusA_LassoESM.npy\n",
      "Shape of embeddings: (1121, 1280)\n",
      "Loading model: VanillaESM\n",
      "Number of sequences: 1121\n",
      "Embeddings saved to: FusA_VanillaESM.npy\n",
      "Shape of embeddings: (1121, 1280)\n",
      "Loading model: PeptideESM\n",
      "Number of sequences: 1121\n",
      "Embeddings saved to: FusA_PeptideESM_650M.npy\n",
      "Shape of embeddings: (1121, 1280)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_file = '../data/data_for_substrate_tolerance_prediction/FusA_tolerance_dataset.csv'\n",
    "    for model_name in MODELS.keys():\n",
    "        process_embeddings(data_file, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f603c2a-7f48-4915-bad7-97c66b3a4829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
