{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa19615-332a-4c86-b1d9-f8fd255b63af",
   "metadata": {},
   "source": [
    "# **Example notebook for predicting cyclase and peptide substrate pairs**\n",
    "**This notebook demonstrates how to predict the cyclase and peptide substrate pairs using LassoESM embeddings. The model architecture incorporates a cross-attention layer to learn interactions between cyclase and peptide substrate. The dataset, consisting of 6,599 positive and 6,599 negative cyclase-peptide pairs, is stored in the \"data/data_for_cyclase_peptide_pair_prediction\" folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2c5f4f-073d-4c67-97c7-e5472eb05478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, balanced_accuracy_score, roc_auc_score, precision_score\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876bc0b-d0bd-421f-86d5-bd4d22eedbce",
   "metadata": {},
   "source": [
    "### **1. Model Architecture**\n",
    "**Cross-Attention Mechanism**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dcc754-b940-45b4-ad6c-adc8420a12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    # Implements a Cross-Attention mechanism to learn interactions between cyclase and peptide substrate embeddings.\n",
    "    def __init__(self):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(1280, 1280))  # Weight matrix for queries\n",
    "        self.W_key = nn.Parameter(torch.rand(1280, 1280))    # Weight matrix for keys\n",
    "        self.W_value = nn.Parameter(torch.rand(1280, 1280))  # Weight matrix for values\n",
    "\n",
    "    def forward(self, x_1, x_2, attn_mask=None):\n",
    "        # Compute queries, keys, and values\n",
    "        \"\"\"\n",
    "        query: Tensor of shape [batch_size, len_peptide, esm_dim]\n",
    "        value: Tensor of shape [batch_size, len_cyclase, esm_dim]\n",
    "        attn_mask: Attention mask to ignore padding residues\n",
    "        \"\"\"\n",
    "        query = torch.matmul(x_1, self.W_query)\n",
    "        key = torch.matmul(x_2, self.W_key)\n",
    "        value = torch.matmul(x_2, self.W_value)\n",
    "\n",
    "        # Compute attention scores\n",
    "        attn_scores = torch.matmul(query, key.transpose(-2, -1))\n",
    "        scaled_attn_scores = attn_scores / math.sqrt(query.size(-1))\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(attn_mask == 0, float('-inf'))  # mask the padding residues\n",
    "        \n",
    "        attn_weights = F.softmax(scaled_attn_scores, dim=-1)\n",
    "        \n",
    "        # Apply attention weights to values\n",
    "        output = torch.matmul(attn_weights, value)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84ca214-f39c-42fd-bdb9-439c838547cc",
   "metadata": {},
   "source": [
    "**MLP Model with Cross-Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f20a367-9e21-460e-9218-e42bf2bf7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model with CrossAttention\n",
    "class MLPWithAttention(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPWithAttention, self).__init__()\n",
    "        self.cross_attention = CrossAttention()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, cyclase, substrate, cyclase_mask, substrate_mask):\n",
    "        # Apply cross-attention mechanism\n",
    "        attn_mask = torch.matmul(substrate_mask.unsqueeze(-1).float(), cyclase_mask.unsqueeze(1).float())\n",
    "        x_1, _ = self.cross_attention(substrate, cyclase, attn_mask)   # reweighted cyclase embeddings\n",
    "\n",
    "        # Average embeddings along the sequence length dimension\n",
    "        x_1_avg = torch.mean(x_1, dim=1)\n",
    "        substrate_avg = torch.mean(substrate, dim=1)\n",
    "        \n",
    "        # Concatenate averaged embeddings and pass through MLP layers\n",
    "        x = torch.cat((x_1_avg, substrate_avg), dim=1)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd1b0f-c948-4d79-8ec7-2af77cae663a",
   "metadata": {},
   "source": [
    "### **2. Embedding Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cd30c7-6dae-4f06-b05f-94025251c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get representation from Vanilla ESM model\n",
    "def get_rep_from_VanillaESM(sequence):\n",
    "    token_ids = esm_tokenizer(sequence, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        results = esm_model(token_ids.input_ids, output_hidden_states=True)\n",
    "    representations = results.hidden_states[33][0]\n",
    "    return representations.cpu().numpy()\n",
    "\n",
    "# Function to get representation from LassoESM model\n",
    "def get_rep_from_LassoESM(sequence):\n",
    "    token_ids = LassoESM_tokenizer(sequence, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        results = LassoESM_model(token_ids.input_ids, output_hidden_states=True)\n",
    "    representations = results.hidden_states[33][0]\n",
    "    return representations.cpu().numpy()\n",
    "\n",
    "# Function to pad the ESM embeddings\n",
    "def pad_esm_embedding(embedding, max_length):\n",
    "    embedding_tensor = torch.tensor(embedding, dtype=torch.float32)\n",
    "    pad_length = max_length - embedding.shape[0]\n",
    "    padding = torch.zeros((pad_length, embedding.shape[1]), dtype=torch.float32)\n",
    "    embedding_tensor = torch.cat((embedding_tensor, padding), dim=0)\n",
    "    \n",
    "    # Create attention mask\n",
    "    attn_mask = torch.ones(max_length, dtype=torch.float32)\n",
    "    attn_mask[embedding.shape[0]:] = 0\n",
    "    attn_mask[0] = 0  # BOS token\n",
    "    attn_mask[embedding.shape[0] - 1] = 0  # EOS token\n",
    "    \n",
    "    return embedding_tensor, attn_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e35d93f-facc-476e-aa6f-211a774019f9",
   "metadata": {},
   "source": [
    "### **3. Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae144fc8-21ca-43ef-8de1-4fb9ef557e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    # Custom PyTorch dataset for cyclase and peptide substrate pairs.\n",
    "    def __init__(self, cyclase_sequences, substrate_sequences, labels, max_cyclase_length, max_substrate_length):\n",
    "        self.cyclase_sequences = cyclase_sequences\n",
    "        self.substrate_sequences = substrate_sequences\n",
    "        self.labels = labels\n",
    "        self.max_cyclase_length = max_cyclase_length\n",
    "        self.max_substrate_length = max_substrate_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cyclase_seq = self.cyclase_sequences[idx]\n",
    "        substrate_seq = self.substrate_sequences[idx]\n",
    "        \n",
    "        # Pad cyclase sequence and create mask\n",
    "        cyclase_embedding, cyclase_mask = pad_esm_embedding(get_rep_from_VanillaESM(cyclase_seq), self.max_cyclase_length)\n",
    "        \n",
    "        # Pad substrate sequence and create mask\n",
    "        substrate_embedding, substrate_mask = pad_esm_embedding(get_rep_from_LassoESM(substrate_seq), self.max_substrate_length)\n",
    "        \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return cyclase_embedding, substrate_embedding, cyclase_mask, substrate_mask, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f056f924-d582-4f32-a637-96088baa6fa8",
   "metadata": {},
   "source": [
    "### **4. Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea850a6-010f-4577-aabc-6feb2b9743c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=25):\n",
    "    # Trains the model and saves the best version based on validation loss\n",
    "    min_val_loss = np.inf\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for cyclase, substrate, cyclase_mask, substrate_mask, labels in train_loader:\n",
    "            cyclase, substrate, cyclase_mask, substrate_mask, labels = cyclase.to(device), substrate.to(device), cyclase_mask.to(device), substrate_mask.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(cyclase, substrate, cyclase_mask, substrate_mask)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # Evaluate the model on validation data\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for cyclase, substrate, cyclase_mask, substrate_mask, labels in val_loader:\n",
    "                cyclase, substrate, cyclase_mask, substrate_mask, labels = cyclase.to(device), substrate.to(device), cyclase_mask.to(device), substrate_mask.to(device), labels.to(device)\n",
    "                outputs = model(cyclase, substrate, cyclase_mask, substrate_mask)\n",
    "                loss = criterion(outputs, labels.unsqueeze(1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        if min_val_loss > val_loss:\n",
    "            print(f'Val Loss Decreased({min_val_loss:.4f} to {val_loss:.4f}) Saving The Model')\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'saved_best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d54518-40e1-4ad3-8e9a-aff160da8b6b",
   "metadata": {},
   "source": [
    "### **5. Model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3748cdfc-bef8-47bc-b795-1d598d108cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    # Evaluates the model using balanced accuracy, recall, AUC, and precision.\n",
    "    model.load_state_dict(torch.load(\"saved_best_model.pth\"))\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for cyclase, substrate, cyclase_mask, substrate_mask, labels in dataloader:\n",
    "            cyclase, substrate, cyclase_mask, substrate_mask, labels = cyclase.to(device), substrate.to(device), cyclase_mask.to(device), substrate_mask.to(device), labels.to(device)\n",
    "            outputs = model(cyclase, substrate, cyclase_mask, substrate_mask)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            all_preds.extend(preds.squeeze().tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "    \n",
    "    balanced_accuracy = balanced_accuracy_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    \n",
    "    return balanced_accuracy, recall, auc, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327f699-2a97-4003-8b40-65d239685948",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    esm_model = AutoModelForMaskedLM.from_pretrained(\"facebook/esm2_t33_650M_UR50D\").to(device) #Load VanillaESM (ESM2)\n",
    "    esm_tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")\n",
    "    esm_model.eval()\n",
    "    LassoESM_model = AutoModelForMaskedLM.from_pretrained(\"ShuklaGroupIllinois/LassoESM\").to(device) #Load LassoESM from hugging face\n",
    "    LassoESM_tokenizer = AutoTokenizer.from_pretrained(\"ShuklaGroupIllinois/LassoESM\")\n",
    "    LassoESM_model.eval()\n",
    "\n",
    "    # Load labels\n",
    "    data = pd.read_csv('../data/data_for_cyclase_peptide_pair_prediction/Cyclase_substrate_pairs_pos_neg_with_filter.csv') # Load processed cyclase-peptide pairs dataset (containing positive samples and synthetic negative samples)\n",
    "    Cyclase_seq = data.iloc[:, 0].tolist()\n",
    "    substrate_seq = data.iloc[:, 1].tolist()\n",
    "    labels = data.iloc[:, 2].tolist()\n",
    "\n",
    "    # Calculate max lengths for padding\n",
    "    max_cyclase_length = max(len(seq) for seq in Cyclase_seq) + 2\n",
    "    max_substrate_length = max(len(seq) for seq in substrate_seq) + 2\n",
    "\n",
    "    # Split data into train, validation, and test sets\n",
    "    Cyclase_train, Cyclase_temp, Substrate_train, Substrate_temp, ys_train, ys_temp = train_test_split(Cyclase_seq, substrate_seq, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "    Cyclase_val, Cyclase_test, Substrate_val, Substrate_test, ys_val, ys_test = train_test_split(Cyclase_temp, Substrate_temp, ys_temp, test_size=0.5, stratify=ys_temp, random_state=42)\n",
    "\n",
    "    # Create dataset and dataloaders\n",
    "    train_dataset = CustomDataset(Cyclase_train, Substrate_train, ys_train, max_cyclase_length, max_substrate_length)\n",
    "    val_dataset = CustomDataset(Cyclase_val, Substrate_val, ys_val, max_cyclase_length, max_substrate_length)\n",
    "    test_dataset = CustomDataset(Cyclase_test, Substrate_test, ys_test, max_cyclase_length, max_substrate_length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    input_size = 1280 * 2\n",
    "    model = MLPWithAttention(input_size).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, epochs=25)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    balanced_accuracy, recall, auc, precision = evaluate_model(model, test_loader)\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "    print(\"Recall (True Positive Rate):\", recall)\n",
    "    print(\"AUC:\", auc)\n",
    "    print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03f470-fdc4-495d-9a1e-01ba70050d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
